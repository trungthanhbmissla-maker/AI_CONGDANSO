import os
from flask import Flask, jsonify, request
from flask_cors import CORS
from dotenv import load_dotenv
import google.generativeai as genai
from google.api_core.exceptions import ResourceExhausted

# ====================================================
# 1ï¸âƒ£ Cáº¥u hÃ¬nh ban Ä‘áº§u
# ====================================================
load_dotenv()

app = Flask(__name__)
CORS(app)

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY or not GOOGLE_API_KEY.strip():
    raise RuntimeError("âŒ GOOGLE_API_KEY chÆ°a Ä‘Æ°á»£c set trong mÃ´i trÆ°á»ng (Render / .env)")

try:
    genai.configure(api_key=GOOGLE_API_KEY)
    print("âœ… Gemini API configured OK")
except Exception as e:
    print(f"âŒ Lá»—i cáº¥u hÃ¬nh Gemini API: {e}")
    raise
    
'''GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY or GOOGLE_API_KEY.strip() == "":
    GOOGLE_API_KEY = "AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxxx" #ÄÆ°a lÃªn onrender cáº§n thay Ä‘á»•i Ä‘á»ƒ khÃ´ng lá»™ key
    print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y GOOGLE_API_KEY trong .env â†’ Ä‘ang dÃ¹ng key dá»± phÃ²ng trong code.")

if not GOOGLE_API_KEY:
    raise ValueError("âŒ KhÃ´ng tÃ¬m tháº¥y GOOGLE_API_KEY. Vui lÃ²ng Ä‘áº·t trong file .env hoáº·c trong code fallback.")

try:
    genai.configure(api_key=GOOGLE_API_KEY)
    print("âœ… Cáº¥u hÃ¬nh Gemini API thÃ nh cÃ´ng.")
except Exception as e:
    print(f"âŒ Lá»—i khi cáº¥u hÃ¬nh Gemini API: {e}")
    raise'''

MODELS_TO_TRY = [
    "gemini-2.5-flash",
    "gemini-2.5-pro",
    "gemini-2.0-flash-lite",
    "gemini-2.0-flash-lite-001"
]

# ====================================================
# 2ï¸âƒ£ HÃ m gá»i Gemini an toÃ n
# ====================================================
'''def generate_text(prompt, safety_settings=None, generation_config=None):
    """
    Gá»i Gemini an toÃ n vá»›i nhiá»u fallback:
    - há»— trá»£ response.candidates[*].content.parts (cÅ©)
    - há»— trá»£ response.text hoáº·c response.output_text (má»›i)
    - luÃ´n tráº£ vá» string (khÃ´ng tráº£ None) â€” náº¿u khÃ´ng cÃ³ ná»™i dung sáº½ tráº£ message thÃ´ng bÃ¡o
    """
    safety_settings = safety_settings or []
    generation_config = generation_config or {"max_output_tokens": 300, "temperature": 0.8}

    last_error = None
    for model_name in MODELS_TO_TRY:
        try:
            print(f"ğŸ”„ Thá»­ model: {model_name}")
            model = genai.GenerativeModel(model_name=model_name)
            response = model.generate_content(
                prompt,
                safety_settings=safety_settings,
                generation_config=generation_config,
            )

            # 1) Náº¿u Ä‘á»‘i tÆ°á»£ng response cÃ³ thuá»™c tÃ­nh 'candidates' kiá»ƒu cÅ©
            try:
                if hasattr(response, "candidates") and response.candidates:
                    candidate = response.candidates[0]
                    # candidate.content.parts (trÆ°á»ng há»£p báº¡n dÃ¹ng trÆ°á»›c)
                    if hasattr(candidate, "content") and candidate.content:
                        parts = getattr(candidate.content, "parts", None)
                        if parts:
                            text = "".join([getattr(p, "text", "") for p in parts if getattr(p, "text", None)])
                            if text and text.strip():
                                print(f"âœ… ThÃ nh cÃ´ng (candidates.parts) vá»›i {model_name}")
                                return text.strip()

                    # fallback: candidate may have text directly
                    if hasattr(candidate, "text") and candidate.text:
                        t = candidate.text.strip()
                        if t:
                            print(f"âœ… ThÃ nh cÃ´ng (candidate.text) vá»›i {model_name}")
                            return t

            except Exception as e:
                # khÃ´ng dá»«ng, thá»­ cÃ¡c dáº¡ng khÃ¡c
                print(f"âš ï¸ KhÃ´ng láº¥y Ä‘Æ°á»£c tá»« candidates: {e}")

            # 2) Náº¿u response cÃ³ .text hoáº·c .output_text (má»™t sá»‘ SDK tráº£ text trá»±c tiáº¿p)
            if hasattr(response, "text") and response.text:
                t = response.text.strip()
                if t:
                    print(f"âœ… ThÃ nh cÃ´ng (response.text) vá»›i {model_name}")
                    return t

            if hasattr(response, "output_text") and response.output_text:
                t = response.output_text.strip()
                if t:
                    print(f"âœ… ThÃ nh cÃ´ng (response.output_text) vá»›i {model_name}")
                    return t

            # 3) Má»™t sá»‘ API tráº£ dict-like trong str form; cá»‘ parse fallback
            try:
                # Convert to string and return non-empty
                s = str(response)
                if s and len(s) > 20:  # trÃ¡nh tráº£ cÃ¡c chuá»—i ngáº¯n vÃ´ nghÄ©a
                    print(f"âœ… ThÃ nh cÃ´ng (str(response)) vá»›i {model_name}")
                    return s.strip()
            except Exception:
                pass

            # náº¿u Ä‘áº¿n Ä‘Ã¢y: response khÃ´ng chá»©a text rÃµ rÃ ng, tiáº¿p tá»¥c model khÃ¡c
            last_error = f"No text in response for model {model_name}"
            print(f"âš ï¸ {last_error}")

        except ResourceExhausted:
            print(f"âš ï¸ Model {model_name} háº¿t quota, thá»­ model khÃ¡c...")
            last_error = f"ResourceExhausted:{model_name}"
            continue
        except Exception as e:
            print(f"âŒ Lá»—i gá»i model {model_name}: {e}")
            last_error = str(e)
            continue

    # Náº¿u khÃ´ng cÃ³ model nÃ o tráº£ vá» ná»™i dung há»£p lá»‡ -> tráº£ fallback rÃµ rÃ ng
    fallback_msg = ("âš ï¸ Há»‡ thá»‘ng AI hiá»‡n khÃ´ng tráº£ ná»™i dung rÃµ rÃ ng. "
                    "Xin thá»­ láº¡i sau hoáº·c liÃªn há»‡ quáº£n trá»‹ viÃªn. "
                    "Chi tiáº¿t lá»—i: " + (last_error or "unknown"))
    print(fallback_msg)
    return fallback_msg'''
def generate_text(prompt, safety_settings=None, generation_config=None):
    #raise RuntimeError("ğŸ”¥ ÄANG VÃ€O generate_text Má»šI ğŸ”¥")
    safety_settings = safety_settings or []
    generation_config = generation_config or {
        "max_output_tokens": 300,
        "temperature": 0.8
    }

    last_error = None

    for model_name in MODELS_TO_TRY:
        print(f"ğŸ”„ ÄANG THá»¬ MODEL: {model_name}")

        try:
            model = genai.GenerativeModel(model_name=model_name)
            response = model.generate_content(
                prompt,
                safety_settings=safety_settings,
                generation_config=generation_config,
            )

            # ===== Láº¤Y TEXT =====
            if hasattr(response, "text") and response.text:
                print(f"âœ… OK: response.text tá»« {model_name}")
                return response.text.strip()

            if hasattr(response, "candidates") and response.candidates:
                c = response.candidates[0]
                if hasattr(c, "content") and hasattr(c.content, "parts"):
                    text = "".join(p.text for p in c.content.parts if hasattr(p, "text"))
                    if text.strip():
                        print(f"âœ… OK: candidates.parts tá»« {model_name}")
                        return text.strip()

            raise ValueError("KhÃ´ng cÃ³ text há»£p lá»‡ trong response")

        except ResourceExhausted as e:
            print(f"âš ï¸ QUOTA Háº¾T táº¡i {model_name}: {e}")
            last_error = f"ResourceExhausted:{model_name}"
            continue

        except Exception as e:
            print(f"âŒ MODEL {model_name} Lá»–I: {type(e).__name__} | {e}")
            last_error = f"{model_name}:{e}"
            continue

    return (
        "âš ï¸ Há»‡ thá»‘ng AI hiá»‡n khÃ´ng kháº£ dá»¥ng.\n"
        "Vui lÃ²ng thá»­ láº¡i sau.\n"
        f"Chi tiáº¿t lá»—i cuá»‘i: {last_error}"
    )
# ====================================================
# ğŸ›°ï¸ TRáº M 1 â€“ KHAI THÃC Dá»® LIá»†U & THÃ”NG TIN
# ====================================================
@app.route("/api/station1-info-literacy", methods=["POST"])
def station1_info_literacy():
    try:
        data = request.get_json(silent=True) or {}
        mode = data.get("mode", "generate_task")
        answer = data.get("answer", "")
        task = data.get("task", "")
        topic = data.get("topic", "tin giáº£ vá» trÆ°á»ng há»c")

        if mode == "generate_task":
            prompt = f"""
            Báº¡n lÃ  AI giÃ¡o dá»¥c CHIRON26 giÃºp há»c sinh rÃ¨n luyá»‡n ká»¹ nÄƒng xÃ¡c thá»±c thÃ´ng tin.
            HÃ£y táº¡o **2 cÃ¢u há»i tráº¯c nghiá»‡m A/B** xoay quanh chá»§ Ä‘á» "{topic}" (tin giáº£, thÃ´ng tin sai lá»‡ch).
            
            Cáº¥u trÃºc báº¯t buá»™c:
            TÃŒNH HUá»NG 1: [MÃ´ táº£ ngáº¯n gá»n vá» má»™t tin Ä‘á»“n/tin giáº£]
            CÃ‚U Há»I: [CÃ¢u há»i vá» hÃ nh Ä‘á»™ng nÃªn lÃ m]
            A. [HÃ nh Ä‘á»™ng sai/thiáº¿u kiá»ƒm chá»©ng]
            B. [HÃ nh Ä‘á»™ng Ä‘Ãºng/kiá»ƒm chá»©ng nguá»“n tin]
            
            (TÆ°Æ¡ng tá»± cho TÃ¬nh huá»‘ng 2)
            
            QUAN TRá»ŒNG: KHÃ”NG Ä‘Æ°á»£c kÃ¨m theo Ä‘Ã¡p Ã¡n Ä‘Ãºng hay lá»i giáº£i thÃ­ch á»Ÿ cuá»‘i (Ä‘á»ƒ há»c sinh tá»± lÃ m).
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.5})
            return jsonify({"station": 1, "response": result})

        elif mode == "evaluate":
            prompt = f"""
            Báº¡n lÃ  giÃ¡m kháº£o cháº¥m thi tráº¯c nghiá»‡m ká»¹ nÄƒng thÃ´ng tin.
            
            1. Äá»€ BÃ€I:
            {task}

            2. Há»ŒC SINH CHá»ŒN:
            {answer}

            3. YÃŠU Cáº¦U CHáº¤M:
            - XÃ¡c Ä‘á»‹nh Ä‘Ã¡p Ã¡n Ä‘Ãºng cá»§a tá»«ng tÃ¬nh huá»‘ng (ÄÃ¡p Ã¡n Ä‘Ãºng lÃ  hÃ nh Ä‘á»™ng kiá»ƒm chá»©ng thÃ´ng tin, tÃ¬m nguá»“n chÃ­nh thá»‘ng).
            - So sÃ¡nh vá»›i lá»±a chá»n cá»§a há»c sinh.
            - TÃ­nh tá»•ng sá»‘ cÃ¢u Ä‘Ãºng (trÃªn 2 cÃ¢u).

            4. Äá»ŠNH Dáº NG TRáº¢ Lá»œI Báº®T BUá»˜C (DÃ²ng Ä‘áº§u tiÃªn):
            SCORE: x/2
            
            (Trong Ä‘Ã³ x lÃ  sá»‘ cÃ¢u Ä‘Ãºng. VÃ­ dá»¥: SCORE: 0/2, SCORE: 1/2, SCORE: 2/2).
            
            Sau dÃ²ng SCORE má»›i Ä‘Æ°á»£c viáº¿t giáº£i thÃ­ch chi tiáº¿t dÆ°á»›i 100 tá»« vÃ¬ sao Ä‘Ãºng/sai.
            """
            
            # Giáº£m temperature xuá»‘ng 0.5 Ä‘á»ƒ cháº¥m Ä‘iá»ƒm chÃ­nh xÃ¡c, khÃ´ng "vÄƒn vá»Ÿ"
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.5})
            return jsonify({"station": 1, "feedback": result})

        else:
            return jsonify({"error": "Invalid mode"}), 400

    except Exception as e:
        print("âŒ Lá»—i tráº¡m 1:", e)
        return jsonify({"error": str(e)}), 500


# ====================================================
# ğŸ’¬ TRáº M 2 â€“ GIAO TIáº¾P & Há»¢P TÃC Sá»
# ====================================================
@app.route("/api/station2-digital-collab", methods=["POST"])
def station2_digital_collab():
    try:
        data = request.get_json(silent=True) or {}
        mode = data.get("mode", "generate_task")
        answer = data.get("answer", "")
        task = data.get("task", "")

        if mode == "generate_task":
            prompt = """
            Báº¡n lÃ  AI giÃ¡o dá»¥c CHIRON26 giÃºp há»c sinh huáº¥n luyá»‡n ká»¹ nÄƒng giao tiáº¿p & há»£p tÃ¡c trong mÃ´i trÆ°á»ng sá»‘.
            HÃ£y táº¡o **2 tÃ¬nh huá»‘ng ngáº¯n (2â€“3 cÃ¢u)** vá» há»c sinh lÃ m viá»‡c nhÃ³m trá»±c tuyáº¿n,
            má»—i tÃ¬nh huá»‘ng cÃ³ **má»™t cÃ¢u há»i tráº¯c nghiá»‡m A/B** Ä‘á»ƒ há»c sinh chá»n cÃ¡ch á»©ng xá»­ Ä‘Ãºng.
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.5})
            return jsonify({"station": 2, "response": result})

        elif mode == "evaluate":
            prompt = f"""
            Báº¡n lÃ  giÃ¡m kháº£o cháº¥m thi tráº¯c nghiá»‡m vá» GIAO TIáº¾P & Há»¢P TÃC Sá».

            1. Äá»€ BÃ€I:
            {task}

            2. Há»ŒC SINH CHá»ŒN:
            {answer}

            3. YÃŠU Cáº¦U:
            - XÃ¡c Ä‘á»‹nh Ä‘Ã¡p Ã¡n Ä‘Ãºng cho tá»«ng tÃ¬nh huá»‘ng.
            - So sÃ¡nh vá»›i lá»±a chá»n cá»§a há»c sinh.
            - Äáº¿m sá»‘ cÃ¢u Ä‘Ãºng (trÃªn tá»•ng sá»‘ 2 cÃ¢u).

            4. Äá»ŠNH Dáº NG TRáº¢ Lá»œI Báº®T BUá»˜C (DÃ²ng Ä‘áº§u tiÃªn):
            SCORE: x/2

            Sau dÃ²ng SCORE má»›i Ä‘Æ°á»£c viáº¿t pháº§n nháº­n xÃ©t chi tiáº¿t, ngáº¯n gá»n, xÃºc tÃ­ch khoáº£ng 100 tá»«.
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.5})
            return jsonify({"station": 2, "response": result})

        elif mode == "evaluate":
            prompt = f"""
            Nhiá»‡m vá»¥:
            {task}

            CÃ¢u tráº£ lá»i cá»§a há»c sinh:
            {answer}

            HÃ£y cháº¥m vÃ  pháº£n há»“i ngáº¯n gá»n dÆ°á»›i 100 tá»«, nÃªu Ä‘iá»ƒm máº¡nh/yáº¿u trong há»£p tÃ¡c sá»‘.
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.5})
            return jsonify({"station": 2, "feedback": result})

        else:
            return jsonify({"error": "Invalid mode"}), 400

    except Exception as e:
        print("âŒ Lá»—i tráº¡m 2:", e)
        return jsonify({"error": str(e)}), 500


# ====================================================
# ğŸ¨ TRáº M 3 â€“ SÃNG Táº O Ná»˜I DUNG Sá» (chat)
# ====================================================

@app.route("/api/station3-content-creation", methods=["POST"])
def station3_content_creation():
    try:
        data = request.get_json(silent=True) or {}
        user_message = data.get("message", "")
        if not user_message:
            user_message = "Xin chÃ o, tÃ´i muá»‘n táº¡o ná»™i dung sá»‘ an toÃ n vÃ  sÃ¡ng táº¡o."

        prompt = f"""
        Báº¡n lÃ  AI giÃ¡o dá»¥c CHIRON26 giÃºp há»c sinh huáº¥n luyá»‡n nÄƒng lá»±c sÃ¡ng táº¡o ná»™i dung sá»‘.
        Há»c sinh nÃ³i: "{user_message}"
        HÃ£y pháº£n há»“i nhÆ° cá»‘ váº¥n sÃ¡ng táº¡o, gá»£i Ã½ Ã½ tÆ°á»Ÿng (bÃ i Ä‘Äƒng, video, poster)
        vÃ  nháº¥n máº¡nh Ä‘áº¡o Ä‘á»©c, báº£n quyá»n, trÃ¡ch nhiá»‡m khi sÃ¡ng táº¡o ná»™i dung.
        KhÃ´ng nÃªn quÃ¡ dÃ i, chá»‰ cáº§n khoáº£ng 10 dÃ²ng.
        """
        text = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.85})
        return jsonify({"station": 3, "response": text})

    except Exception as e:
        print("âŒ Lá»—i tráº¡m 3:", e)
        return jsonify({"error": str(e)}), 500


# ====================================================
# ğŸ›¡ï¸ TRáº M 4 â€“ AN TOÃ€N Sá»
# ====================================================
@app.route("/api/station4-safety", methods=["POST"])
def station4_safety():
    try:
        data = request.get_json(silent=True) or {}
        mode = data.get("mode", "generate_task")
        answer = data.get("answer", "")
        task = data.get("task", "")

        if mode == "generate_task":
            # ThÃªm yÃªu cáº§u KHÃ”NG kÃ¨m Ä‘Ã¡p Ã¡n Ä‘á»ƒ trÃ¡nh lá»™
            prompt = """
            Báº¡n lÃ  AI giÃ¡o dá»¥c CHIRON26 giÃºp há»c sinh huáº¥n luyá»‡n ká»¹ nÄƒng an toÃ n sá»‘.
            HÃ£y táº¡o **2 tÃ¬nh huá»‘ng tráº¯c nghiá»‡m ngáº¯n** vá»: báº£o máº­t tÃ i khoáº£n, lá»«a Ä‘áº£o trá»±c tuyáº¿n (phishing), hoáº·c báº¯t náº¡t máº¡ng.
            
            Cáº¥u trÃºc báº¯t buá»™c:
            TÃŒNH HUá»NG 1: [Ná»™i dung]
            CÃ‚U Há»I: [CÃ¢u há»i]
            A. [Lá»±a chá»n 1]
            B. [Lá»±a chá»n 2]
            
            (TÆ°Æ¡ng tá»± cho TÃ¬nh huá»‘ng 2)
            QUAN TRá»ŒNG: KHÃ”NG Ä‘Æ°á»£c viáº¿t Ä‘Ã¡p Ã¡n Ä‘Ãºng hay giáº£i thÃ­ch á»Ÿ cuá»‘i.
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.5})
            return jsonify({"station": 4, "response": result})

        elif mode == "evaluate":
            # --- Sá»¬A QUAN TRá»ŒNG Táº I ÄÃ‚Y ---
            prompt = f"""
            Báº¡n lÃ  giÃ¡m kháº£o cháº¥m thi tráº¯c nghiá»‡m vá» AN TOÃ€N Sá».
            
            1. Äá»€ BÃ€I:
            {task}

            2. Há»ŒC SINH CHá»ŒN:
            {answer}

            3. YÃŠU Cáº¦U:
            - XÃ¡c Ä‘á»‹nh Ä‘Ã¡p Ã¡n Ä‘Ãºng dá»±a trÃªn kiáº¿n thá»©c an toÃ n thÃ´ng tin.
            - So sÃ¡nh vá»›i Ä‘Ã¡p Ã¡n há»c sinh chá»n.
            - Äáº¿m sá»‘ cÃ¢u Ä‘Ãºng (trÃªn tá»•ng sá»‘ 2 cÃ¢u).

            4. Äá»ŠNH Dáº NG TRáº¢ Lá»œI Báº®T BUá»˜C (DÃ²ng Ä‘áº§u tiÃªn):
            SCORE: x/2
            
            (Trong Ä‘Ã³ x lÃ  sá»‘ cÃ¢u Ä‘Ãºng. VÃ­ dá»¥: SCORE: 0/2, SCORE: 1/2, SCORE: 2/2).
            
            Sau dÃ²ng SCORE má»›i Ä‘Æ°á»£c viáº¿t pháº§n giáº£i thÃ­ch chi tiáº¿t Ä‘Ãºng/sai cho tá»«ng cÃ¢u khoáº£ng 50 tá»«.
            KHÃ”NG chÃºc má»«ng náº¿u há»c sinh lÃ m sai.
            """
            
            # Giáº£m temperature xuá»‘ng 0.5 Ä‘á»ƒ AI cháº¥m nghiÃªm tÃºc hÆ¡n, Ã­t "sÃ¡ng táº¡o" lung tung
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.5})
            return jsonify({"station": 4, "feedback": result})

        else:
            return jsonify({"error": "Invalid mode"}), 400

    except Exception as e:
        print("âŒ Lá»—i tráº¡m 4:", e)
        return jsonify({"error": str(e)}), 500

# ====================================================
# ğŸ§© TRáº M 5 â€“ GIáº¢I QUYáº¾T Váº¤N Äá»€
# ====================================================
@app.route("/api/station5-problem-solving", methods=["POST"])
def station5_problem_solving():
    try:
        data = request.get_json(silent=True) or {}
        mode = data.get("mode", "generate_task")
        answer = data.get("answer", "")
        task = data.get("task", "")

        if mode == "generate_task":
            prompt = """
            Báº¡n lÃ  AI giÃ¡o dá»¥c CHIRON26 giÃºp há»c sinh huáº¥n luyá»‡n ká»¹ nÄƒng giáº£i quyáº¿t váº¥n Ä‘á» báº±ng cÃ´ng nghá»‡ sá»‘.
            HÃ£y táº¡o **2 tÃ¬nh huá»‘ng (3â€“4 cÃ¢u)** mÃ´ táº£ sá»± cá»‘ ká»¹ thuáº­t (máº¥t dá»¯ liá»‡u, lá»—i pháº§n má»m...),
            má»—i tÃ¬nh huá»‘ng cÃ³ má»™t cÃ¢u há»i tráº¯c nghiá»‡m A/B gá»£i Ã½ cÃ¡ch xá»­ lÃ½.
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.5})
            return jsonify({"station": 5, "response": result})

        elif mode == "evaluate":
            prompt = f"""
            Báº¡n lÃ  giÃ¡m kháº£o cháº¥m thi tráº¯c nghiá»‡m vá» GIáº¢I QUYáº¾T Váº¤N Äá»€ Sá».

            1. Äá»€ BÃ€I:
            {task}

            2. Há»ŒC SINH CHá»ŒN:
            {answer}

            3. YÃŠU Cáº¦U:
            - XÃ¡c Ä‘á»‹nh phÆ°Æ¡ng Ã¡n xá»­ lÃ½ Ä‘Ãºng cho tá»«ng tÃ¬nh huá»‘ng.
            - So sÃ¡nh vá»›i cÃ¢u tráº£ lá»i cá»§a há»c sinh.
            - Äáº¿m sá»‘ cÃ¢u Ä‘Ãºng (trÃªn tá»•ng sá»‘ 2 cÃ¢u).

            4. Äá»ŠNH Dáº NG TRáº¢ Lá»œI Báº®T BUá»˜C (DÃ²ng Ä‘áº§u tiÃªn):
            SCORE: x/2

            Sau Ä‘Ã³ má»›i Ä‘Æ°á»£c viáº¿t nháº­n xÃ©t, khÃ´ng lan man, xÃºc tÃ­ch khoáº£ng 100 tá»«.
            """ 
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.5})
            return jsonify({"station": 5, "feedback": result})

        else:
            return jsonify({"error": "Invalid mode"}), 400

    except Exception as e:
        print("âŒ Lá»—i tráº¡m 5:", e)
        return jsonify({"error": str(e)}), 500



# ====================================================
# ğŸ¤– TRáº M 6 â€“ Äáº O Äá»¨C & TRÃ TUá»† NHÃ‚N Táº O (chat)
# ====================================================
@app.route("/api/station6-ai-ethics", methods=["POST"])
def station6_ai_ethics():
    try:
        data = request.get_json(silent=True) or {}
        user_message = data.get("message", "")
        if not user_message:
            user_message = "ChÃºng ta nÃªn dÃ¹ng AI nhÆ° tháº¿ nÃ o Ä‘á»ƒ cÃ³ trÃ¡ch nhiá»‡m?"
        prompt = f"""
        Báº¡n lÃ  AI giÃ¡o dá»¥c cÃ³ tÃªn CHIRON26. Báº¡n sáº½ cÃ¹ng tháº£o luáº­n vá»›i há»c sinh vá» **á»¨ng dá»¥ng trÃ­ tuá»‡ nhÃ¢n táº¡o**.
        Há»c sinh nÃ³i: "{user_message}"
        HÃ£y pháº£n há»“i báº±ng cÃ¡ch gá»£i má»Ÿ, giÃºp há»c sinh hiá»ƒu:
        - AI nÃªn Ä‘Æ°á»£c dÃ¹ng cÃ³ trÃ¡ch nhiá»‡m, cÃ´ng báº±ng, an toÃ n.
        - TrÃ¡nh láº¡m dá»¥ng, sao chÃ©p hoáº·c táº¡o ná»™i dung gÃ¢y háº¡i.
        - KhÃ´ng quÃ¡ dÃ i, khÃ´ng quÃ¡ 10 dÃ²ng.
        """
        text = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.7})
        return jsonify({"station": 6, "response": text})

    except Exception as e:
        print("âŒ Lá»—i tráº¡m 6:", e)
        return jsonify({"error": str(e)}), 500


# ====================================================
# âœ… KIá»‚M TRA ROUTE
# ====================================================
@app.route("/", methods=["GET"])
def home():
    return jsonify({
        "routes": [
            "/api/station1-info-literacy",
            "/api/station2-digital-collab",
            "/api/station3-content-creation",
            "/api/station4-safety",
            "/api/station5-problem-solving",
            "/api/station6-ai-ethics"
        ],
        "status": "âœ… Backend AI CÃ´ng dÃ¢n sá»‘ Ä‘ang cháº¡y"
    })


# ====================================================
# ğŸ”Ÿ Cháº¡y server
# ====================================================
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    app.run(host="0.0.0.0", port=port, debug=False)





