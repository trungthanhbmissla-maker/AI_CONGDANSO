import os
from flask import Flask, jsonify, request
from flask_cors import CORS
from dotenv import load_dotenv
import google.generativeai as genai
from google.api_core.exceptions import ResourceExhausted

# ====================================================
# 1Ô∏è‚É£ C·∫•u h√¨nh ban ƒë·∫ßu
# ====================================================
load_dotenv()

app = Flask(__name__)
CORS(app)

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY or GOOGLE_API_KEY.strip() == "":
    GOOGLE_API_KEY = "AIzaSyD0zS4tkhhWin5sSFQZ5C32MWTuQYr4xC8"
    print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y GOOGLE_API_KEY trong .env ‚Üí ƒëang d√πng key d·ª± ph√≤ng trong code.")

if not GOOGLE_API_KEY:
    raise ValueError("‚ùå Kh√¥ng t√¨m th·∫•y GOOGLE_API_KEY. Vui l√≤ng ƒë·∫∑t trong file .env ho·∫∑c trong code fallback.")

try:
    genai.configure(api_key=GOOGLE_API_KEY)
    print("‚úÖ C·∫•u h√¨nh Gemini API th√†nh c√¥ng.")
except Exception as e:
    print(f"‚ùå L·ªói khi c·∫•u h√¨nh Gemini API: {e}")
    raise

MODELS_TO_TRY = [
    "gemini-2.5-flash",
    "gemini-2.5-pro",
    "gemini-2.0-flash-lite",
    "gemini-2.0-flash-lite-001",
    "gemini-2.5-flash-lite",
    "gemini-2.5-flash-lite-preview-09-2025",
    "gemini-2.5-computer-use-preview-10-2025",
    "gemini-2.5-pro-preview-tts"

]

# ====================================================
# 2Ô∏è‚É£ H√†m g·ªçi Gemini an to√†n
# ====================================================
def generate_text(prompt, safety_settings=None, generation_config=None):
    """
    G·ªçi Gemini an to√†n v·ªõi nhi·ªÅu fallback:
    - h·ªó tr·ª£ response.candidates[*].content.parts (c≈©)
    - h·ªó tr·ª£ response.text ho·∫∑c response.output_text (m·ªõi)
    - lu√¥n tr·∫£ v·ªÅ string (kh√¥ng tr·∫£ None) ‚Äî n·∫øu kh√¥ng c√≥ n·ªôi dung s·∫Ω tr·∫£ message th√¥ng b√°o
    """
    safety_settings = safety_settings or []
    generation_config = generation_config or {"max_output_tokens": 300, "temperature": 0.8}

    last_error = None
    for model_name in MODELS_TO_TRY:
        try:
            print(f"üîÑ Th·ª≠ model: {model_name}")
            model = genai.GenerativeModel(model_name=model_name)
            response = model.generate_content(
                prompt,
                safety_settings=safety_settings,
                generation_config=generation_config,
            )

            # 1) N·∫øu ƒë·ªëi t∆∞·ª£ng response c√≥ thu·ªôc t√≠nh 'candidates' ki·ªÉu c≈©
            try:
                if hasattr(response, "candidates") and response.candidates:
                    candidate = response.candidates[0]
                    # candidate.content.parts (tr∆∞·ªùng h·ª£p b·∫°n d√πng tr∆∞·ªõc)
                    if hasattr(candidate, "content") and candidate.content:
                        parts = getattr(candidate.content, "parts", None)
                        if parts:
                            text = "".join([getattr(p, "text", "") for p in parts if getattr(p, "text", None)])
                            if text and text.strip():
                                print(f"‚úÖ Th√†nh c√¥ng (candidates.parts) v·ªõi {model_name}")
                                return text.strip()

                    # fallback: candidate may have text directly
                    if hasattr(candidate, "text") and candidate.text:
                        t = candidate.text.strip()
                        if t:
                            print(f"‚úÖ Th√†nh c√¥ng (candidate.text) v·ªõi {model_name}")
                            return t

            except Exception as e:
                # kh√¥ng d·ª´ng, th·ª≠ c√°c d·∫°ng kh√°c
                print(f"‚ö†Ô∏è Kh√¥ng l·∫•y ƒë∆∞·ª£c t·ª´ candidates: {e}")

            # 2) N·∫øu response c√≥ .text ho·∫∑c .output_text (m·ªôt s·ªë SDK tr·∫£ text tr·ª±c ti·∫øp)
            if hasattr(response, "text") and response.text:
                t = response.text.strip()
                if t:
                    print(f"‚úÖ Th√†nh c√¥ng (response.text) v·ªõi {model_name}")
                    return t

            if hasattr(response, "output_text") and response.output_text:
                t = response.output_text.strip()
                if t:
                    print(f"‚úÖ Th√†nh c√¥ng (response.output_text) v·ªõi {model_name}")
                    return t

            # 3) M·ªôt s·ªë API tr·∫£ dict-like trong str form; c·ªë parse fallback
            try:
                # Convert to string and return non-empty
                s = str(response)
                if s and len(s) > 20:  # tr√°nh tr·∫£ c√°c chu·ªói ng·∫Øn v√¥ nghƒ©a
                    print(f"‚úÖ Th√†nh c√¥ng (str(response)) v·ªõi {model_name}")
                    return s.strip()
            except Exception:
                pass

            # n·∫øu ƒë·∫øn ƒë√¢y: response kh√¥ng ch·ª©a text r√µ r√†ng, ti·∫øp t·ª•c model kh√°c
            last_error = f"No text in response for model {model_name}"
            print(f"‚ö†Ô∏è {last_error}")

        except ResourceExhausted:
            print(f"‚ö†Ô∏è Model {model_name} h·∫øt quota, th·ª≠ model kh√°c...")
            last_error = f"ResourceExhausted:{model_name}"
            continue
        except Exception as e:
            print(f"‚ùå L·ªói g·ªçi model {model_name}: {e}")
            last_error = str(e)
            continue

    # N·∫øu kh√¥ng c√≥ model n√†o tr·∫£ v·ªÅ n·ªôi dung h·ª£p l·ªá -> tr·∫£ fallback r√µ r√†ng
    fallback_msg = ("‚ö†Ô∏è H·ªá th·ªëng AI hi·ªán kh√¥ng tr·∫£ n·ªôi dung r√µ r√†ng. "
                    "Xin th·ª≠ l·∫°i sau ho·∫∑c li√™n h·ªá qu·∫£n tr·ªã vi√™n. "
                    "Chi ti·∫øt l·ªói: " + (last_error or "unknown"))
    print(fallback_msg)
    return fallback_msg
# ====================================================
# üõ∞Ô∏è TR·∫†M 1 ‚Äì KHAI TH√ÅC D·ªÆ LI·ªÜU & TH√îNG TIN
# ====================================================
@app.route("/api/station1-info-literacy", methods=["POST"])
def station1_info_literacy():
    try:
        data = request.get_json(silent=True) or {}
        mode = data.get("mode", "generate_task")
        answer = data.get("answer", "")
        task = data.get("task", "")
        topic = data.get("topic", "tin gi·∫£ v·ªÅ tr∆∞·ªùng h·ªçc")

        if mode == "generate_task":
            prompt = f"""
            B·∫°n l√† AI gi√°o d·ª•c CHIRON26 gi√∫p h·ªçc sinh hu·∫•n luy·ªán nƒÉng l·ª±c khai th√°c d·ªØ li·ªáu v√† th√¥ng tin.
            H√£y t·∫°o **2 c√¢u h·ªèi tr·∫Øc nghi·ªám ng·∫Øn** (m·ªói c√¢u 2‚Äì4 c√¢u m√¥ t·∫£ + c√¢u h·ªèi c√≥ 2 l·ª±a ch·ªçn A/B)
            xoay quanh ch·ªß ƒë·ªÅ "{topic}". M·ªói c√¢u n√™n c√≥ t√¨nh hu·ªëng nh·ªè v·ªÅ tin gi·∫£, th√¥ng tin sai l·ªách
            v√† y√™u c·∫ßu h·ªçc sinh x√°c minh ngu·ªìn tin.
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.8})
            return jsonify({"station": 1, "response": result})

        elif mode == "evaluate":
            prompt = f"""
            D∆∞·ªõi ƒë√¢y l√† nhi·ªám v·ª• g·ªëc:
            {task}

            C√¢u tr·∫£ l·ªùi c·ªßa h·ªçc sinh:
            {answer}

            H√£y **ch·∫•m ƒëi·ªÉm v√† ph·∫£n h·ªìi chi ti·∫øt** (2‚Äì3 c√¢u), khuy·∫øn kh√≠ch h·ªçc sinh c·∫£i thi·ªán.
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.7})
            return jsonify({"station": 1, "feedback": result})

        else:
            return jsonify({"error": "Invalid mode"}), 400

    except Exception as e:
        print("‚ùå L·ªói tr·∫°m 1:", e)
        return jsonify({"error": str(e)}), 500


# ====================================================
# üí¨ TR·∫†M 2 ‚Äì GIAO TI·∫æP & H·ª¢P T√ÅC S·ªê
# ====================================================
@app.route("/api/station2-digital-collab", methods=["POST"])
def station2_digital_collab():
    try:
        data = request.get_json(silent=True) or {}
        mode = data.get("mode", "generate_task")
        answer = data.get("answer", "")
        task = data.get("task", "")

        if mode == "generate_task":
            prompt = """
            B·∫°n l√† AI gi√°o d·ª•c CHIRON26 gi√∫p h·ªçc sinh hu·∫•n luy·ªán k·ªπ nƒÉng giao ti·∫øp & h·ª£p t√°c trong m√¥i tr∆∞·ªùng s·ªë.
            H√£y t·∫°o **2 t√¨nh hu·ªëng ng·∫Øn (2‚Äì3 c√¢u)** v·ªÅ h·ªçc sinh l√†m vi·ªác nh√≥m tr·ª±c tuy·∫øn,
            m·ªói t√¨nh hu·ªëng c√≥ **m·ªôt c√¢u h·ªèi tr·∫Øc nghi·ªám A/B** ƒë·ªÉ h·ªçc sinh ch·ªçn c√°ch ·ª©ng x·ª≠ ƒë√∫ng.
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.85})
            return jsonify({"station": 2, "response": result})

        elif mode == "evaluate":
            prompt = f"""
            Nhi·ªám v·ª•:
            {task}

            C√¢u tr·∫£ l·ªùi c·ªßa h·ªçc sinh:
            {answer}

            H√£y ch·∫•m v√† ph·∫£n h·ªìi ng·∫Øn g·ªçn, n√™u ƒëi·ªÉm m·∫°nh/y·∫øu trong h·ª£p t√°c s·ªë.
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.75})
            return jsonify({"station": 2, "feedback": result})

        else:
            return jsonify({"error": "Invalid mode"}), 400

    except Exception as e:
        print("‚ùå L·ªói tr·∫°m 2:", e)
        return jsonify({"error": str(e)}), 500


# ====================================================
# üé® TR·∫†M 3 ‚Äì S√ÅNG T·∫†O N·ªòI DUNG S·ªê (chat)
# ====================================================

@app.route("/api/station3-content-creation", methods=["POST"])
def station3_content_creation():
    try:
        data = request.get_json(silent=True) or {}
        user_message = data.get("message", "")
        if not user_message:
            user_message = "Xin ch√†o, t√¥i mu·ªën t·∫°o n·ªôi dung s·ªë an to√†n v√† s√°ng t·∫°o."

        prompt = f"""
        B·∫°n l√† AI gi√°o d·ª•c CHIRON26 gi√∫p h·ªçc sinh hu·∫•n luy·ªán nƒÉng l·ª±c s√°ng t·∫°o n·ªôi dung s·ªë.
        H·ªçc sinh n√≥i: "{user_message}"
        H√£y ph·∫£n h·ªìi nh∆∞ c·ªë v·∫•n s√°ng t·∫°o, g·ª£i √Ω √Ω t∆∞·ªüng (b√†i ƒëƒÉng, video, poster)
        v√† nh·∫•n m·∫°nh ƒë·∫°o ƒë·ª©c, b·∫£n quy·ªÅn, tr√°ch nhi·ªám khi s√°ng t·∫°o n·ªôi dung.
        Kh√¥ng n√™n qu√° d√†i, ch·ªâ c·∫ßn kho·∫£ng 10 d√≤ng.
        """
        text = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.85})
        return jsonify({"station": 3, "response": text})

    except Exception as e:
        print("‚ùå L·ªói tr·∫°m 3:", e)
        return jsonify({"error": str(e)}), 500


# ====================================================
# üõ°Ô∏è TR·∫†M 4 ‚Äì AN TO√ÄN S·ªê
# ====================================================
@app.route("/api/station4-safety", methods=["POST"])
def station4_safety():
    try:
        data = request.get_json(silent=True) or {}
        mode = data.get("mode", "generate_task")
        answer = data.get("answer", "")
        task = data.get("task", "")

        if mode == "generate_task":
            prompt = """
            B·∫°n l√† AI gi√°o d·ª•c CHIRON26 gi√∫p h·ªçc sinh hu·∫•n luy·ªán k·ªπ nƒÉng an to√†n s·ªë cho h·ªçc sinh.
            H√£y t·∫°o **2 t√¨nh hu·ªëng ng·∫Øn (2‚Äì3 c√¢u)** v·ªÅ b·∫£o m·∫≠t t√†i kho·∫£n, l·ª´a ƒë·∫£o tr·ª±c tuy·∫øn,
            ho·∫∑c khi b·ªã b·∫Øt n·∫°t m·∫°ng. M·ªói t√¨nh hu·ªëng c√≥ c√¢u h·ªèi tr·∫Øc nghi·ªám A/B.
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.8})
            return jsonify({"station": 4, "response": result})

        elif mode == "evaluate":
            prompt = f"""
            Nhi·ªám v·ª•:
            {task}

            C√¢u tr·∫£ l·ªùi c·ªßa h·ªçc sinh:
            {answer}

            H√£y ch·∫•m v√† ph·∫£n h·ªìi th√¢n thi·ªán, nh·∫•n m·∫°nh h√†nh vi an to√†n s·ªë ƒë√∫ng.
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.7})
            return jsonify({"station": 4, "feedback": result})

        else:
            return jsonify({"error": "Invalid mode"}), 400

    except Exception as e:
        print("‚ùå L·ªói tr·∫°m 4:", e)
        return jsonify({"error": str(e)}), 500


# ====================================================
# üß© TR·∫†M 5 ‚Äì GI·∫¢I QUY·∫æT V·∫§N ƒê·ªÄ
# ====================================================
@app.route("/api/station5-problem-solving", methods=["POST"])
def station5_problem_solving():
    try:
        data = request.get_json(silent=True) or {}
        mode = data.get("mode", "generate_task")
        answer = data.get("answer", "")
        task = data.get("task", "")

        if mode == "generate_task":
            prompt = """
            B·∫°n l√† AI gi√°o d·ª•c CHIRON26 gi√∫p h·ªçc sinh hu·∫•n luy·ªán k·ªπ nƒÉng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ b·∫±ng c√¥ng ngh·ªá s·ªë.
            H√£y t·∫°o **2 t√¨nh hu·ªëng (3‚Äì4 c√¢u)** m√¥ t·∫£ s·ª± c·ªë k·ªπ thu·∫≠t (m·∫•t d·ªØ li·ªáu, l·ªói ph·∫ßn m·ªÅm...),
            m·ªói t√¨nh hu·ªëng c√≥ m·ªôt c√¢u h·ªèi tr·∫Øc nghi·ªám A/B g·ª£i √Ω c√°ch x·ª≠ l√Ω.
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.8})
            return jsonify({"station": 5, "response": result})

        elif mode == "evaluate":
            prompt = f"""
            Nhi·ªám v·ª•:
            {task}

            C√¢u tr·∫£ l·ªùi c·ªßa h·ªçc sinh:
            {answer}

            H√£y ph·∫£n h·ªìi logic, khuy·∫øn kh√≠ch h·ªçc sinh √°p d·ª•ng quy tr√¨nh: x√°c ƒë·ªãnh nguy√™n nh√¢n ‚Äì th·ª≠ gi·∫£i ph√°p ‚Äì ƒë√°nh gi√° k·∫øt qu·∫£.
            """
            result = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.75})
            return jsonify({"station": 5, "feedback": result})

        else:
            return jsonify({"error": "Invalid mode"}), 400

    except Exception as e:
        print("‚ùå L·ªói tr·∫°m 5:", e)
        return jsonify({"error": str(e)}), 500



# ====================================================
# ü§ñ TR·∫†M 6 ‚Äì ƒê·∫†O ƒê·ª®C & TR√ç TU·ªÜ NH√ÇN T·∫†O (chat)
# ====================================================
@app.route("/api/station6-ai-ethics", methods=["POST"])
def station6_ai_ethics():
    try:
        data = request.get_json(silent=True) or {}
        user_message = data.get("message", "")
        if not user_message:
            user_message = "Ch√∫ng ta n√™n d√πng AI nh∆∞ th·∫ø n√†o ƒë·ªÉ c√≥ tr√°ch nhi·ªám?"
        prompt = f"""
        B·∫°n l√† AI gi√°o d·ª•c c√≥ t√™n CHIRON26. B·∫°n s·∫Ω c√πng th·∫£o lu·∫≠n v·ªõi h·ªçc sinh v·ªÅ **·ª®ng d·ª•ng tr√≠ tu·ªá nh√¢n t·∫°o**.
        H·ªçc sinh n√≥i: "{user_message}"
        H√£y ph·∫£n h·ªìi b·∫±ng c√°ch g·ª£i m·ªü, gi√∫p h·ªçc sinh hi·ªÉu:
        - AI n√™n ƒë∆∞·ª£c d√πng c√≥ tr√°ch nhi·ªám, c√¥ng b·∫±ng, an to√†n.
        - Tr√°nh l·∫°m d·ª•ng, sao ch√©p ho·∫∑c t·∫°o n·ªôi dung g√¢y h·∫°i.
        - Kh√¥ng qu√° d√†i, kh√¥ng qu√° 10 d√≤ng.
        """
        text = generate_text(prompt, generation_config={"max_output_tokens": 2048, "temperature": 0.7})
        return jsonify({"station": 6, "response": text})

    except Exception as e:
        print("‚ùå L·ªói tr·∫°m 6:", e)
        return jsonify({"error": str(e)}), 500


# ====================================================
# ‚úÖ KI·ªÇM TRA ROUTE
# ====================================================
@app.route("/", methods=["GET"])
def home():
    return jsonify({
        "routes": [
            "/api/station1-info-literacy",
            "/api/station2-digital-collab",
            "/api/station3-content-creation",
            "/api/station4-safety",
            "/api/station5-problem-solving",
            "/api/station6-ai-ethics"
        ],
        "status": "‚úÖ Backend AI C√¥ng d√¢n s·ªë ƒëang ch·∫°y"
    })


# ====================================================
# üîü Ch·∫°y server
# ====================================================
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    app.run(host="0.0.0.0", port=port, debug=False)
